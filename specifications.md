# Projet "Orion-Dynamic" : Orchestrateur de Ressources √† Inventaire Dynamique et Gestion de Baux

* **Mati√®re :** D√©ploiement & Infrastructure as Code (IaC)  
* **Objectif :** Plateforme PaaS simulant un parc de ressources ‚Äúauto-enregistrantes‚Äù, avec gestion des baux, migration en cas de panne et d√©-provisionnement automatique √† l‚Äôexpiration.

---

## Contexte et Objectifs

Le Control Plane doit‚ÄØ:

1. **D√©couvrir dynamiquement les Workers** via un Agent qui s‚Äôenregistre sur l‚ÄôAPI.  
2. **Exposer une API s√©curis√©e** pour louer des ressources pour une dur√©e d√©termin√©e.  
3. **Surveiller la sant√© des n≈ìuds** avec un Scheduler qui fait du SSH pour d√©terminer leur √©tat.  
4. **Migrer automatiquement les clients** si un n≈ìud tombe en panne.  
5. **Lib√©rer et nettoyer les n≈ìuds** √† l‚Äôexpiration du bail.

---

## Architecture

**Control Plane :**

- Reverse Proxy (Caddy, HTTPS client / HTTP agent, Load Balancing)
- API Python (gestion enregistrement + location, scalable)
- Autoscaler (Monitoring CPU + Scaling Docker)
- Scheduler (Health Check, Migration, Expiration, Concurrency safety)
- MariaDB (DB inventaire + baux)

**Data Plane :**

- Workers (containers Alpine avec SSH + Agent Python)

---

## Sch√©ma Flux (Mermaid)

```mermaid
flowchart LR
    Client["Client (curl/CLI)"]

    subgraph DATA["Monde Externe (Data Plane)"]
        Worker["Workers (Pr√©-existants)<br/>Agent 'agent.py' d√©ploy√©"]
    end

    subgraph CONTROL["Notre Infrastructure (Control Plane)"]
        RP["Reverse Proxy (Caddy)<br/>:443 (Client)<br/>:80 (Agent)"]
        API["Rest API (Scalable)<br/>:8080"]
        SCHED["Scheduler (Replica-safe)"]
        AS["Autoscaler"]
        DB[(MariaDB)]
    end

    %% Scaling
    AS -.->|"Monitors CPU & Scales"| API
    
    %% Flux 0 : Enregistrement auto
    Worker -- "Flux 0: POST /api/register" --> RP

    %% Flux 1 : Location client
    Client -->|"Flux 1: POST /api/rent" | RP

    %% Flux 2 : Proxy ‚Üí API
    RP -->|"Flux 2 (LB)" | API

    %% Flux 3 : API et Scheduler interagissent avec DB
    API -->|"Flux 3" | DB
    SCHED -->|"Flux 3" | DB

    %% Flux 4 : Provisioning via Ansible
    API -.->|"Flux 4: Provisioning SSH (Ansible)" | Worker

    %% Flux 5 : QoS / Cleanup via Scheduler
    SCHED -.->|"Flux 5: Health Check & Cleanup SSH (Ansible)" | Worker
```
**Explication des flux :**

* **Flux 0 (Enregistrement) :** L'`Agent` sur le Worker contacte `POST /api/register` (via le Proxy) pour s'ajouter √† la `Database`.
* **Flux 1 (Location Client) :** Le `Client` envoie `POST /api/rent` (via Proxy) pour louer un n≈ìud pour une dur√©e N.
* **Flux 2 (Proxy Pass) :** Le `Proxy` transf√®re les requ√™tes √† l'`API`.
* **Flux 3 (√âtat) :** L'`API` et le `Scheduler` lisent/√©crivent constamment dans la `Database` (source de v√©rit√©).
* **Flux 4 (Provisioning) :** L'`API` (suite √† une location) ou le `Scheduler` (suite √† une migration) initie une connexion **SSH sortante** pour provisionner un Worker (via Ansible).
* **Flux 5 (QoS / Cleanup) :** Le `Scheduler` initie des connexions **SSH sortantes** pour v√©rifier la sant√© (Health Check) ou nettoyer un Worker (Expiration de bail via Ansible).

---

## üõ†Ô∏è Fonctionnalit√©s

### 1. Agent (`agent.py`)
- Envoie `hostname`, `ip`, `ssh_port` au Control Plane via `POST /api/workers/register`.  
- Exception Docker‚ÄØ: si IP interne `172.17.*`, utiliser `host.docker.internal`.  
- G√®re les retries.

### 2. API
#### `POST /api/workers/register`
- Ajoute/Met √† jour un Worker (`hostname`, `ip`, `ssh_port`, `status='unknown'`).  

#### `POST /api/rent`
- Input : `duration_hours`, `count`, optionnel `ssh_password`.  
- V√©rifie n≈ìuds `alive` et `allocated = FALSE`.  
- Calcule `lease_end`.  
- Met `allocated = TRUE` et `allocated_to = user`.  
- Provision via Ansible (`create_user.yml`).  
- Retourne `host_ip`, `ssh_port`, `client_user`, `client_pass`, `leased_until`.  

### 3. Scheduler
#### Health Check (30s)
- **Concurrence** : Utilise `SELECT ... FOR UPDATE SKIP LOCKED` pour permettre √† plusieurs instance de Scheduler de travailler en parall√®le sans conflit.
- SSH sur tous les Workers.  
- MAJ `status` (`alive`/`dead`), `last_checked`.  

#### Migration (10s)
- N≈ìuds `dead` et `allocated = TRUE` ‚Üí trouver nouveau Worker `alive`.  
- Provisionner via Ansible, mettre √† jour DB.  

#### Expiration des baux (1min)
- N≈ìuds `allocated = TRUE` et `lease_end <= NOW()`.  
- D√©-provision via Ansible (`delete_user.yml`).  
- Lib√©ration DB (`allocated = FALSE`, `allocated_to = NULL`, `lease_end_at = NULL`).

### 4. Autoscaler
- **Monitoring** : V√©rifie la charge CPU de tous les conteneurs API toutes les 5s.
- **Scaling UP** : Si charge > 70%, ajoute un r√©plica (max 5).
- **Scaling DOWN** : Si charge < 20%, retire un r√©plica (min 2).
- **Action** : Utilise la commande `docker compose up --scale` √† chaud.

---

## üì¶ Livrables

1. **Code Python** : API, Scheduler, Agent.  
2. **IaC** : `docker-compose.yml`, `Dockerfile` pour API, Scheduler, Worker, Caddyfile.  
3. **Playbooks Ansible** : `create_user.yml`, `delete_user.yml`.  
4. **Scripts** : lancement des Workers (`launch_workers.sh`).  
5. **DB** : `init.sql` (tables `nodes`, `users`, `rentals`).  
6. **Documentation** : `README.md`.

---

### Remarques

- Le r√¥le admin peut √™tre d√©fini avec‚ÄØ:

```sql
UPDATE users SET role='admin' WHERE username='admin';
```
- Les IP Docker sont remplac√©es par host.docker.internal pour que l‚ÄôAPI/SSH fonctionne depuis le Control Plane.

- allocated est toujours mis √† TRUE lors d‚Äôune location pour √©viter les conflits.

- La structure DB comprend maintenant ip pour les Workers.