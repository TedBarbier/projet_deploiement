### 1. üìã Titre du Projet

**Projet "Orion-Static" : Orchestrateur de Ressources √† Inventaire Statique et Haute Disponibilit√©**

* **Mati√®re :** D√©ploiement & Infrastructure as Code (IaC)
* **Objectif :** Simuler une plateforme de location de ressources (conteneurs) bas√©e sur un inventaire **connu et pr√©-d√©fini**. La plateforme doit garantir la QoS en surveillant activement l'√©tat des ressources et en migrant les clients en cas de panne.

---

### 2. üéØ Contexte et Objectifs

Le but est de cr√©er un syst√®me de location de ressources (PaaS) o√π le parc de "n≈ìuds" (workers) est connu √† l'avance par l'orchestrateur.

L'orchestrateur doit :
1.  **G√©rer un inventaire statique** (d√©fini en configuration).
2.  **Exposer une API s√©curis√©e** (via un Reverse Proxy) pour les clients d√©sirant louer une ressource.
3.  **Surveiller la sant√© (Health Check)** : Un service `Scheduler` doit activement sonder (via SSH) tous les n≈ìuds (lou√©s ou non) pour conna√Ætre leur √©tat ("alive" / "dead").
4.  **Provisionner** les ressources √† la demande (cr√©er un utilisateur) en utilisant Ansible (appel√© par l'API).
5.  **G√©rer la r√©silience :** En cas de d√©tection de panne d'un n≈ìud lou√©, le `Scheduler` doit d√©clencher la migration du client vers un n≈ìud sain.

---

### 3. üèóÔ∏è Architecture Globale

Le syst√®me est compos√© de deux ensembles :
* **Le "Control Plane" (R√©seau Docker "lab") :** Contient la logique de gestion.
    * `Reverse Proxy` (Caddy/Nginx) : Point d'entr√©e pour les clients humains.
    * `API` (Go/Gin) : G√®re les demandes de location.
    * `Scheduler` (Go) : G√®re la surveillance et la migration.
    * `Database` (MariaDB) : Stocke l'√©tat de l'inventaire et des locations.
* **Le "Data Plane" (H√¥te Docker) :**
    * `Workers` (Conteneurs Alpine) : Les ressources passives. Ex√©cutent un serveur SSH et sont mapp√©s sur des ports de l'h√¥te (ex: `22221 -> 22`).

---

### 4. üåê Sch√©ma R√©seau D√©taill√© (Parc Connu)

Ce sch√©ma illustre le mod√®le √† inventaire statique o√π le Control Plane initie les connexions vers les Workers.

```mermaid
flowchart LR
    %% D√©finir le style pour les connexions SSH en pointill√©s
    linkStyle 3 stroke-dasharray: 5 5
    linkStyle 4 stroke-dasharray: 5 5

    %% Entit√©s Hors R√©seau
    Client["Client (curl/CLI)"]

    %% Subgraph pour l'H√¥te Docker (Data Plane)
    subgraph HOTE [Host (Docker Engine)]
        Workers["Workers (Alpine)<br/>Port 22221..N -> 22"]
    end

    %% Subgraph pour le R√©seau de Contr√¥le (Control Plane)
    subgraph LAB [lab_network]
        direction LR
        RP["Reverse Proxy (Caddy)<br/>HTTPS :443"]
        API["Go API (Gin)<br/>:8080"]
        SCHED["Go Scheduler"]
        DB[(MariaDB)]

        RP -->|Flux 2: HTTP :8080| API
        API -->|Flux 3: SQL| DB
        SCHED -->|Flux 3: SQL| DB
    end

    %% Connexions Externes vers Internes
    Client -->|Flux 1: HTTPS :443| RP

    %% Connexions du Control Plane vers le Data Plane (SSH)
    API -.->|Flux 4: Provisioning<br/>(SSH via host.docker.internal)| Workers
    SCHED -.->|Flux 5: Health Check<br/>(SSH via host.docker.internal)| Workers
```
**Explication des flux :**

* **Flux 1 (Location Client) :** Le `Client` envoie `POST /api/rent` au `Reverse Proxy` (point d'entr√©e public).
* **Flux 2 (Proxy Pass) :** Le `Proxy` transf√®re la requ√™te √† l'`API (Go/Gin)`.
* **Flux 3 (√âtat) :** L'`API` et le `Scheduler` lisent/√©crivent constamment dans la `Database` (MariaDB) pour conna√Ætre/modifier l'√©tat des n≈ìuds et des locations.
* **Flux 4 (Provisioning) :** L'`API` (suite √† une location) initie une connexion **SSH sortante** (ex: `ssh host.docker.internal:22221`) vers le `Worker` pour le provisionner (via Ansible).
* **Flux 5 (Health Check / QoS) :** Le `Scheduler` initie des connexions **SSH sortantes** (ex: `ssh host.docker.internal:22221`, `...:22222`, etc.) pour v√©rifier la sant√© de **tous** les `Workers` (lou√©s ou non).

---

### 5. üõ†Ô∏è Fonctionnalit√©s D√©taill√©es

#### 5.1. IaC et D√©ploiement
* **En tant qu'Admin,** je veux un `docker-compose.yml` qui d√©ploie le "Control Plane" (Proxy, API, Scheduler, DB).
* **En tant qu'Admin,** je veux un script s√©par√© (ou un autre Compose) pour lancer le "Data Plane" (les N `Workers` Alpine avec leurs ports SSH mapp√©s).
* L'inventaire des Workers (ex: `host.docker.internal:22221`) est fourni √† l'API et au Scheduler (ex: via un fichier de config ou des variables d'env.).

#### 5.2. API (Go/Gin)
* **`POST /api/rent` :** (Appel√© par le Client, via Proxy)
    1.  Interroge la `DB` pour trouver un `Worker` avec `status = 'alive'` ET `allocated = false`.
    2.  Si aucun n'est trouv√©, renvoie 503 (Service Unavailable).
    3.  Si trouv√©, marque le Worker comme `allocated = true` dans la DB.
    4.  Appelle **Ansible** (Flux 4) pour provisionner ce Worker.
    5.  Renvoie les d√©tails de connexion au client.

#### 5.3. Scheduler (Go) - La QoS
* **T√¢che 1 : Health Check (Toutes les 30s)**
    1.  It√®re sur **TOUT** l'inventaire des Workers (de la DB ou config).
    2.  Pour chaque Worker, tente une connexion SSH (Flux 5).
    3.  Si succ√®s : `UPDATE nodes SET status = 'alive', last_checked = NOW()`.
    4.  Si √©chec : `UPDATE nodes SET status = 'dead', last_checked = NOW()`.
* **T√¢che 2 : Migration (Toutes les 10s)**
    1.  Cherche dans la DB les `Workers` avec `status = 'dead'` ET `allocated = true`.
    2.  Pour chaque cas (une "panne client") :
        a. Trouve un *nouveau* Worker (`status = 'alive'`, `allocated = false`).
        b. Si pas de nouveau Worker dispo, log l'erreur (client en panne).
        c. Si trouv√© :
            i. Appelle **Ansible** (Flux 4) pour provisionner le *nouveau* Worker.
            ii. Met √† jour la DB (ancienne location lib√©r√©e, nouvelle cr√©√©e).
            iii. (Optionnel) Notifie le client du changement d'IP.

---

### 6. üì¶ Livrables Attendus

1.  **Code Source :** Le code Go pour l'API et le Scheduler.
2.  **Fichiers IaC :**
    * `docker-compose.yml` pour le "Control Plane".
    * `Dockerfile` pour l'API (Go, Ansible).
    * `Dockerfile` pour le Scheduler (Go).
    * `Dockerfile` pour le Worker (Alpine, `openssh-server`).
    * Fichier de configuration Nginx/Caddy pour le Proxy.
3.  **Scripts d'Automatisation :**
    * Playbooks Ansible (ex: `create_user.yml`, `delete_user.yml`).
    * Script de lancement des Workers.
4.  **Documentation :** Un `README.md` expliquant l'architecture, comment lancer le Control Plane et le Data Plane, et comment simuler une panne (ex: `docker stop worker_1`).√®
